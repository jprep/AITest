{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T10:10:41.907833Z",
     "start_time": "2025-04-04T10:10:41.776108Z"
    }
   },
   "source": [
    "# Create and store the model\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Ignore UserWarning from Keras and PIL\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='keras')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='PIL')\n",
    "\n",
    "# Set paths to your dataset\n",
    "base_dir = 'PetImages\\\\PetImages1.25K'\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "validation_dir = os.path.join(base_dir, 'Validate')\n",
    "\n",
    "# Set parameters\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Create ImageDataGenerator for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Changed to 'categorical'\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Changed to 'categorical'\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Changed to support multi-category classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Changed to 'categorical_crossentropy'\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the model in the recommended Keras format\n",
    "model.save('multi_category_model.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot training & validation performance if history is defined\n",
    "if history is not None:\n",
    "    # Combined plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(history.history['accuracy'], color='red', label='Training Accuracy')\n",
    "    plt.plot(history.history['loss'], color='red', linestyle='--', linewidth=2, label='Training Loss')\n",
    "    plt.plot(history.history['val_accuracy'], color='green', label='Validation Accuracy')\n",
    "    plt.plot(history.history['val_loss'], color='green', linestyle='--', linewidth=2, label='Validation Loss')\n",
    "    plt.title('Model Training and Validation')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), ncol=1)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Subplots\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], color='red', label='Training Accuracy')\n",
    "    plt.plot(history.history['loss'], color='red', linestyle='--', label='Training Loss')\n",
    "    plt.title('Model Training')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(linewidth=0.5)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['val_accuracy'], color='green', label='Validation Accuracy')\n",
    "    plt.plot(history.history['val_loss'], color='green', linestyle='--', label='Validation Loss')\n",
    "    plt.title('Model Validation')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(linewidth=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'PetImages\\\\PetImages1.25K\\\\Train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 37\u001B[0m\n\u001B[0;32m     34\u001B[0m test_datagen \u001B[38;5;241m=\u001B[39m ImageDataGenerator(rescale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Load training data\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_datagen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow_from_directory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mimg_height\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_width\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcategorical\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Changed to 'categorical'\u001B[39;49;00m\n\u001B[0;32m     42\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Load validation data\u001B[39;00m\n\u001B[0;32m     45\u001B[0m validation_generator \u001B[38;5;241m=\u001B[39m test_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[0;32m     46\u001B[0m     validation_dir,\n\u001B[0;32m     47\u001B[0m     target_size\u001B[38;5;241m=\u001B[39m(img_height, img_width),\n\u001B[0;32m     48\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     49\u001B[0m     class_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# Changed to 'categorical'\u001B[39;00m\n\u001B[0;32m     50\u001B[0m )\n",
      "File \u001B[1;32m~\\.virtualenvs\\AITest-DjU_gHgM\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001B[0m, in \u001B[0;36mImageDataGenerator.flow_from_directory\u001B[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001B[0m\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mflow_from_directory\u001B[39m(\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1122\u001B[0m     directory,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1136\u001B[0m     keep_aspect_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1137\u001B[0m ):\n\u001B[1;32m-> 1138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDirectoryIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1140\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolor_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclasses\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_to_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_to_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_links\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_links\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\AITest-DjU_gHgM\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001B[0m, in \u001B[0;36mDirectoryIterator.__init__\u001B[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001B[0m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m    452\u001B[0m     classes \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 453\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subdir \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(directory)):\n\u001B[0;32m    454\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, subdir)):\n\u001B[0;32m    455\u001B[0m             classes\u001B[38;5;241m.\u001B[39mappend(subdir)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'PetImages\\\\PetImages1.25K\\\\Train'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the model and use it to create predictive functions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('multi_category_model.keras')\n",
    "\n",
    "# Set image size parameters for the model\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "# Define category labels\n",
    "categories = ['Dog', 'Cat']\n",
    "\n",
    "# Function to predict a specific new image\n",
    "def predict_image(img_path):\n",
    "    # Load the image\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalise\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img_array[0])  # Display the image\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()  # Show the image\n",
    "\n",
    "    # Make the prediction\n",
    "    prediction = model.predict(img_array, verbose=1)\n",
    "    predicted_label = categories[np.argmax(prediction)]  # Decodes the prediction\n",
    "    return predicted_label\n",
    "\n",
    "# Test new images\n",
    "# result = predict_image('TestImages\\\\001.jpeg')\n",
    "# print(result)\n",
    "\n",
    "def predict_images_in_folder(folder_path):\n",
    "    print(f'Starting prediction for images in the {folder_path} folder...\\n')\n",
    "\n",
    "    print('Files in folder:')\n",
    "    print(os.listdir(folder_path))\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.jpeg', '.jpg', '.png')) and not filename.startswith('.'):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            print(f'\\nProcessing {filename}...')\n",
    "\n",
    "            img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalise\n",
    "\n",
    "            # Display the image\n",
    "            plt.imshow(img_array[0])  # Display the image\n",
    "            plt.axis('off')  # Hide the axis\n",
    "            plt.show()  # Show the image\n",
    "\n",
    "            prediction = model.predict(img_array, verbose=0)\n",
    "            print(f'Raw prediction output for {filename}: {prediction}')\n",
    "\n",
    "            predicted_label = categories[np.argmax(prediction)]  # Decodes the prediction\n",
    "            print(f'{filename}: {predicted_label}')\n",
    "\n",
    "    print('\\nPrediction completed.')\n",
    "\n",
    "# Test new images in the folder\n",
    "# predict_images_in_folder('TestImages')"
   ],
   "id": "59fc3dfd62c24e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:45:58.008721Z",
     "start_time": "2025-04-04T11:45:58.001575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(os.path.exists('PetImages\\\\PetImages1.25K\\\\Train'))\n",
    "print(os.path.exists('PetImages\\\\PetImages1.25K\\\\Validate'))\n"
   ],
   "id": "73b3c6f8f3a6159e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
